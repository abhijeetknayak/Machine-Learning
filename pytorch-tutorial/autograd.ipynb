{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nayakab/Desktop/python-virtual-env/env/lib/python3.6/site-packages/torch/package/_mock_zipreader.py:17: UserWarning: Failed to initialize NumPy: numpy.core.multiarray failed to import (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:67.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4504,  0.1775, -0.4907], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1036, 0.0315, 0.2408], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x ** 2\n",
    "y.retain_grad()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4252, 2.0010, 2.0580], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y ** 2 + 2 \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobian Vector product - specify the vector or use a scalar\n",
    "#z.sum().backward()\n",
    "vector_v = torch.Tensor(3)\n",
    "z.backward(vector_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.4805e+13,  1.0258e-42, -2.3197e-36])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.5512e+12,  2.8881e-42,  2.3635e-36])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1036, 0.0315, 0.2408])\n"
     ]
    }
   ],
   "source": [
    "# Blocking gradients\n",
    "x.requires_grad_(False)\n",
    "x.detach()\n",
    "x.requires_grad_(True)\n",
    "with torch.no_grad():\n",
    "    # No gradient for y because no gradient for x\n",
    "    y = x ** 2\n",
    "    print(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    output = weights * 3 \n",
    "    output = output.sum()\n",
    "    \n",
    "    output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    # Make Grad zero everytime because Torch keeps accumulating these gradients  \n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nayakab/Desktop/python-virtual-env/env/lib/python3.6/site-packages/torch/package/_mock_zipreader.py:17: UserWarning: Failed to initialize NumPy: numpy.core.multiarray failed to import (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:67.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
     ]
    }
   ],
   "source": [
    "# Computational Graph is created with each calculation\n",
    "import torch \n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "weights = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# Forward\n",
    "y_ = weights * x\n",
    "loss = (y_ - y) ** 2\n",
    "print(loss)\n",
    "\n",
    "loss.backward() \n",
    "print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 === Weight : 1.2, Loss : 30.0\n",
      "Epoch 1 === Weight : 1.6799999618530272, Loss : 4.799999237060547\n",
      "Epoch 2 === Weight : 1.871999988555908, Loss : 0.7680001854896545\n",
      "Epoch 3 === Weight : 1.9487999868392942, Loss : 0.1228799968957901\n",
      "Epoch 4 === Weight : 1.9795200133323667, Loss : 0.019660834223031998\n",
      "Epoch 5 === Weight : 1.9918080282211301, Loss : 0.0031457357108592987\n",
      "Epoch 6 === Weight : 1.9967231869697568, Loss : 0.0005033080233260989\n",
      "Epoch 7 === Weight : 1.99868928194046, Loss : 8.053186320466921e-05\n",
      "Epoch 8 === Weight : 1.999475698471069, Loss : 1.2884394891443662e-05\n",
      "Epoch 9 === Weight : 1.999790253639221, Loss : 2.0613531432900345e-06\n",
      "Epoch 10 === Weight : 1.9999160599708554, Loss : 3.297340072094812e-07\n",
      "Epoch 11 === Weight : 1.9999664139747617, Loss : 5.282345227897167e-08\n",
      "Epoch 12 === Weight : 1.9999865984916685, Loss : 8.487816671731707e-09\n",
      "Epoch 13 === Weight : 1.9999946093559262, Loss : 1.3369572116062045e-09\n",
      "Epoch 14 === Weight : 1.9999978351593015, Loss : 2.1679014139408537e-10\n",
      "Epoch 15 === Weight : 1.9999991369247434, Loss : 3.531397396727698e-11\n",
      "Epoch 16 === Weight : 1.9999996304512022, Loss : 5.076827847005916e-12\n",
      "Epoch 17 === Weight : 1.999999837875366, Loss : 8.988365607365267e-13\n",
      "Epoch 18 === Weight : 1.9999999165534972, Loss : 1.3145040611561853e-13\n",
      "Epoch 19 === Weight : 1.9999999952316283, Loss : 1.3145040611561853e-13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "def forward(input, weights):\n",
    "    return weights * input\n",
    "\n",
    "def loss(Y, Y_pred):\n",
    "    return ((Y_pred - Y) ** 2).mean()\n",
    "\n",
    "def gradient(x, Y, Y_predicted):\n",
    "    return 2 * np.dot(Y_predicted - Y, x).mean()\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    Y_pred = forward(X, w)\n",
    "    l = loss(Y, Y_pred)\n",
    "    w_grad = gradient(X, Y, Y_pred)\n",
    "    \n",
    "    w -= learning_rate * w_grad\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Epoch {} === Weight : {}, Loss : {}\".format(epoch, w, l))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 === Weight : 0.29999998211860657, Loss : 30.0\n",
      "Epoch 10 === Weight : 1.6653136014938354, Loss : 1.1627856492996216\n",
      "Epoch 20 === Weight : 1.934108853340149, Loss : 0.0450688973069191\n",
      "Epoch 30 === Weight : 1.987027645111084, Loss : 0.0017468547448515892\n",
      "Epoch 40 === Weight : 1.9974461793899536, Loss : 6.770494655938819e-05\n",
      "Epoch 50 === Weight : 1.9994971752166748, Loss : 2.6243997126584873e-06\n",
      "Epoch 60 === Weight : 1.9999010562896729, Loss : 1.0175587306093803e-07\n",
      "Epoch 70 === Weight : 1.9999804496765137, Loss : 3.9741685498029256e-09\n",
      "Epoch 80 === Weight : 1.999996304512024, Loss : 1.4670220593870908e-10\n",
      "Epoch 90 === Weight : 1.9999992847442627, Loss : 5.076827847005916e-12\n"
     ]
    }
   ],
   "source": [
    "# Now with Torch\n",
    "import torch\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x, w):\n",
    "    return x * w\n",
    "\n",
    "def loss(Y, Y_pred):\n",
    "    return ((Y_pred - Y) ** 2).mean()\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    Y_pred = forward(X, w)\n",
    "    \n",
    "    l = loss(Y, Y_pred)\n",
    "    \n",
    "    l.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {} === Weight : {}, Loss : {}\".format(epoch, w, l))\n",
    "        \n",
    "    w.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
